{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_classification_website.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0SaD6PwlHhd"
      },
      "source": [
        "Code is used and adapted with permission mainly from \n",
        "- [Deploying a Simple Machine Learning Model into a WebApp using TensorFlow.js](https://towardsdatascience.com/deploying-a-simple-machine-learning-model-into-a-webapp-using-tensorflow-js-3609c297fb04) by Carlos Aguayo\n",
        "\n",
        "Code is also used and adapted from \n",
        "- [Handwritten Digit Recognition using Convolutional Neural Networks in Python with Keras](https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/) by Jason Brownlee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCtUmY1nin6w",
        "cellView": "both"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('tensorflow version', tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GJYzFjDgyPK"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeFoigUnFa05"
      },
      "source": [
        "print('train_images.shape: ', train_images.shape)\n",
        "print('train_labels.shape: ', train_labels.shape)\n",
        "print('test_images.shape: ', test_images.shape)\n",
        "print('test_labels.shape: ', test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiYzyZo_g_dq"
      },
      "source": [
        "# Plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(train_images[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(train_images[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(train_images[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(train_images[3], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uFc-cAMhHSK"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = train_images.shape[1] * train_images.shape[2]\n",
        "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1)).astype('float32')\n",
        "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1)).astype('float32')\n",
        "\n",
        "# Normalize inputs from 0-255 to 0-1\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255\n",
        "\n",
        "# One-hot encode outputs\n",
        "train_labels = np_utils.to_categorical(train_labels)\n",
        "test_labels = np_utils.to_categorical(test_labels)\n",
        "num_classes = test_labels.shape[1]\n",
        "\n",
        "# Define model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "epochs = 30\n",
        "\n",
        "# Fit model to data\n",
        "model.fit(train_images, train_labels, validation_data=(test_images, test_labels), \n",
        "          steps_per_epoch=len(train_images)/batch_size, epochs=epochs, batch_size=batch_size, verbose=2)\n",
        "\n",
        "scores = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbRDcaOtR_Z9"
      },
      "source": [
        "# Save whole model for download\n",
        "model.save(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRZij573atOT"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgBVZH1Fa2zW"
      },
      "source": [
        "!tensorflowjs_converter --input_format keras '/content/model.h5' '/content/model'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}